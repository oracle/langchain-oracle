# Copyright (c) 2025 Oracle and/or its affiliates.
# Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl/

"""LLM for OCI data science model deployment endpoint."""
import os
from typing import Dict, Optional

from langchain_core.language_models.llms import BaseLanguageModel
from langchain_core.utils import get_from_dict_or_env
from langchain_core.utils.utils import secret_from_env
from langchain_openai import OpenAI
from pydantic import Field, SecretStr, model_validator


class BaseOCIModelDeployment(BaseLanguageModel):
    """Base class for LLM deployed on OCI Data Science Model Deployment."""

    auth: dict = Field(default_factory=dict, exclude=True)
    """ADS auth dictionary for OCI authentication:
    https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html.
    This can be generated by calling `ads.common.auth.api_keys()`
    or `ads.common.auth.resource_principal()`. If this is not
    provided then the `ads.common.default_signer()` will be used."""

    openai_api_key: Optional[SecretStr] = Field(
        alias="api_key", default_factory=secret_from_env("OPENAI_API_KEY", default=" ")
    )
    """openai_api_key needs to be a non-empty in order to initialize openai client."""

    model_name: str = Field(default="odsc-llm", alias="model")
    """Model name to use."""

    endpoint: Optional[str] = None
    """For backward compatibility, user may specify the endpoint instead of base_url."""

    @model_validator(mode="before")
    @classmethod
    def oci_auth_and_endpoint(cls, values: Dict) -> Dict:
        """Checks if oracle-ads is installed and
        get credentials/endpoint from environment.
        """
        # Authentication
        # oracle-ads is only required if the http_client is not set
        if not values.get("http_client"):
            try:
                import ads

            except ImportError as ex:
                raise ImportError(
                    "Could not import ads python package. "
                    "Please install it with `pip install oracle_ads`."
                ) from ex

            if not values.get("auth"):
                values["auth"] = ads.common.auth.default_signer()

            from ads.aqua import HttpxOCIAuth, get_httpx_client

            values["http_client"] = get_httpx_client(
                auth=HttpxOCIAuth(values["auth"].get("signer"))
            )

        # Endpoint
        values["endpoint"] = get_from_dict_or_env(
            values,
            "endpoint",
            "OCI_LLM_ENDPOINT",
            default="",
        )

        if values.get("endpoint"):
            values["openai_api_base"] = values["endpoint"]

        if values.get("openai_api_base") and not values["openai_api_base"].endswith(
            "v1"
        ):
            values["openai_api_base"] = os.path.join(values["openai_api_base"], "v1")
        return values


class OCIModelDeploymentLLM(BaseOCIModelDeployment, OpenAI):
    """LLM deployed on OCI Data Science Model Deployment.

    To use, you must provide the model HTTP endpoint from your deployed
    model, e.g. https://modeldeployment.<region>.oci.customer-oci.com/<md_ocid>/predict.

    To authenticate, `oracle-ads` has been used to automatically load
    credentials: https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html

    Make sure to have the required policies to access the OCI Data
    Science Model Deployment endpoint. See:
    https://docs.oracle.com/en-us/iaas/data-science/using/model-dep-policies-auth.htm#model_dep_policies_auth__predict-endpoint

    This class inherits from OpenAI LangChain client.
    You can use all the parameters supported by OpenAI LangChain client.

    Example:

        .. code-block:: python

            from langchain_oci import OCIModelDeploymentLLM

            llm = OCIModelDeploymentLLM(
                endpoint="https://modeldeployment.us-ashburn-1.oci.customer-oci.com/<ocid>/predictWithResponseStream",
                model="odsc-llm",
            )
            llm.stream("tell me a joke.")

    """  # noqa: E501
